apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "kafka.fullname" . }}
  labels:
    {{- include "kafka.labels" . | nindent 4 }}
spec:
  selector:
    matchLabels:
      {{- include "kafka.selectorLabels" . | nindent 6 }}
  serviceName: {{ include "kafka.fullname" . }}-headless
  replicas: 3
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  podManagementPolicy: Parallel
  template:
    metadata:
      labels:
        {{- include "kafka.selectorLabels" . | nindent 8 }}
    spec:
      securityContext:
        fsGroup: 1000
      affinity:
      {{- if .Values.affinity }}
        {{ toYaml .Values.affinity | indent 8 }}
      {{- else }}
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - {{ include "kafka.name" . }}
              topologyKey: kubernetes.io/hostname
            weight: 1
     {{- end }}
      containers:
      - name: kafka-exporter
        image: danielqsj/kafka-exporter:v1.9.0
        imagePullPolicy: IfNotPresent
        ports:
           - containerPort: 2121
             name: metrics
        args:
          - "--kafka.server=localhost:9092"
          - "--web.listen-address=:2121"
        resources:
          limits:
            cpu: 100m
            memory: 128Mi
          requests:
            cpu: 50m
            memory: 64Mi
      - name: {{ .Chart.Name }}
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
        imagePullPolicy: "IfNotPresent"
        image: "docker.io/confluentinc/cp-kafka:{{ .Values.version }}"
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        - name: HOST_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
        - name: POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: {{ include "kafka.zookeeper.ensemble" . | quote }}
        - name: KAFKA_HEAP_OPTS
          value: "-XX:MaxRAMPercentage=75.0 -XX:InitialRAMPercentage=50.0"
        - name: KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE
          value: "false"
        - name: KAFKA_LOG_DIRS
          value: "/var/lib/kafka/data"
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: "false"
        - name: KAFKA_DELETE_TOPIC_ENABLE
          value: "true"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_NUM_PARTITIONS
          value: "3"
        - name: KAFKA_DEFAULT_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_MIN_INSYNC_REPLICAS
          value: "2"
        - name: KAFKA_UNCLEAN_LEADER_ELECTION.ENABLE
          value: "false"
        - name: KAFKA_LOG_FLUSH_INTERVAL_MESSAGES
          value: "10000"
        - name: KAFKA_LOG_FLUSH_INTERVAL_MS
          value: "1000"
        - name: KAFKA_LOG_RETENTION_BYTES
          value: "1073741824"
        - name: KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS
          value: "300000"
        - name: KAFKA_LOG_RETENTION_HOURS
          value: "168"
        - name: KAFKA_LOG_SEGMENT_BYTES
          value: "1073741824"
        - name: KAFKA_MESSAGE_MAX_BYTES
          value: "1048588"
        - name: KAFKA_LOG4J_ROOT_LOGLEVEL
          value: "INFO"
        - name: KAFKA_LOG4J_LOGGERS
          value: "kafka.authorizer.logger=INFO,kafka.controller=INFO"
        - name: KAFKA_LISTENERS
          value: "PLAINTEXT://:9092,EXTERNAL://:9093"
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT"
        command:
        - "sh"
        - "-exc"
        - |
          export KAFKA_BROKER_ID=${HOSTNAME##*-} && \
          export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://{{ include "kafka.listener" . }}:9092,EXTERNAL://127.0.0.1:$((32400 + ${KAFKA_BROKER_ID})) && \
          rm -rf /var/lib/kafka/data/lost+found && \
          exec /etc/confluent/docker/run
        ports:
        - name: tcp-kafka-int
          containerPort: 9092
        - name: tcp-kafka-ext
          containerPort: 9093
        livenessProbe:
          tcpSocket:
            port: tcp-kafka-int
          initialDelaySeconds: 300
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 6
          successThreshold: 1
        readinessProbe:
          tcpSocket:
            port: tcp-kafka-int
          initialDelaySeconds: 120
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 6
          successThreshold: 1
        volumeMounts:
        - name: data
          mountPath: /var/lib/kafka/data
        - name: config
          mountPath: /etc/kafka
        - name: logs
          mountPath: /var/log
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsUser: 1000
          runAsGroup: 1000
          capabilities:
            drop:
            - ALL
        resources:
          {{- toYaml .Values.resources | nindent 12 }}
      volumes:
      - name: config
        emptyDir: {}
      - name: logs
        emptyDir: {}
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: {{ .Values.diskSize | quote }}
