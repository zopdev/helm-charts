apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "kafka.fullname" . }}
  labels:
    {{- include "kafka.labels" . | nindent 4 }}
spec:
  selector:
    matchLabels:
      {{- include "kafka.selectorLabels" . | nindent 6 }}
  serviceName: {{ include "kafka.fullname" . }}-headless
  replicas: {{ .Values.replicaCount }}
  updateStrategy:
    type: RollingUpdate
  podManagementPolicy: Parallel
  template:
    metadata:
      labels:
        {{- include "kafka.selectorLabels" . | nindent 8 }}
    spec:
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      affinity:
      {{- if .Values.affinity }}
        {{ toYaml .Values.affinity | indent 8 }}
      {{- else }}
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - {{ include "kafka.name" . }}
              topologyKey: kubernetes.io/hostname
            weight: 1
     {{- end }}
      containers:
      - name: {{ .Chart.Name }}
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        image: "{{ .Values.image.registry }}/{{ .Values.image.repository }}:{{ .Values.image.tag | default "latest" }}"
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        - name: HOST_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
        - name: POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: {{ include "kafka.zookeeper.ensemble" . | quote }}
        - name: KAFKA_HEAP_OPTS
          value: {{ .Values.heapOpts | quote }}
        - name: KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE
          value: {{ .Values.confluentSupportMetricsEnable | quote }}
        - name: KAFKA_LOG_DIRS
          value: "/var/lib/kafka/data"
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: {{ .Values.autoCreateTopicsEnable | quote }}
        - name: KAFKA_DELETE_TOPIC_ENABLE
          value: {{ .Values.deleteTopicEnable | quote }}
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: {{ .Values.offsetsTopicReplicationFactor | int | quote }}
        - name: KAFKA_NUM_PARTITIONS
          value: {{ .Values.numPartitions | int | quote }}
        - name: KAFKA_DEFAULT_REPLICATION_FACTOR
          value: {{ .Values.defaultReplicationFactor | int | quote }}
        - name: KAFKA_MIN_INSYNC_REPLICAS
          value: {{ .Values.minInsyncReplicas | int | quote }}
        - name: KAFKA_UNCLEAN_LEADER_ELECTION.ENABLE
          value: {{ .Values.uncleanLeaderElectionEnable | quote }}
        - name: KAFKA_LOG_FLUSH_INTERVAL_MESSAGES
          value: {{ .Values.logFlushIntervalMessages | int | quote }}
        - name: KAFKA_LOG_FLUSH_INTERVAL_MS
          value: {{ .Values.logFlushIntervalMs | int | quote }}
        - name: KAFKA_LOG_RETENTION_BYTES
          value: {{ .Values.logRetentionBytes | int | quote }}
        - name: KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS
          value: {{ .Values.logRetentionCheckIntervalMs | int | quote }}
        - name: KAFKA_LOG_RETENTION_HOURS
          value: {{ .Values.logRetentionHours | int | quote }}
        - name: KAFKA_LOG_SEGMENT_BYTES
          value: {{ .Values.logSegmentBytes | int | quote }}
        - name: KAFKA_MESSAGE_MAX_BYTES
          value: {{ .Values.messageMaxBytes | int | quote }}
        - name: KAFKA_LOG4J_ROOT_LOGLEVEL
          value: {{ .Values.log4jRootLoglevel | quote }}
        - name: KAFKA_LOG4J_LOGGERS
          value: {{ .Values.log4jLoggers | quote }}
        - name: KAFKA_LISTENERS
          value: "PLAINTEXT://:{{ .Values.port.kafkaInternal }},EXTERNAL://:{{ .Values.port.kafkaExternal }}"
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT"
        {{- if .Values.acls.enabled }}
        - name: KAFKA_ZOOKEEPER_SET_ACL
          value: "true"
        - name: KAFKA_SUPER_USERS
          value: "User:kafka"
        - name: KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND
          value: "false"
        - name: KAFKA_AUTHORIZER_CLASS_NAME
          value: "kafka.security.authorizer.AclAuthorizer"
        {{- end }}
        command:
        - "sh"
        - "-exc"
        - |
          export KAFKA_BROKER_ID=${HOSTNAME##*-} && \
          {{- if .Values.isDocker }}
          export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://{{ include "kafka.listener" . }}:{{ .Values.port.kafkaInternal }},EXTERNAL://127.0.0.1:$(({{ .Values.externalAccess.initNodePort }} + ${KAFKA_BROKER_ID})) && \
          {{- else }}
          export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://{{ include "kafka.listener" . }}:{{ .Values.port.kafkaInternal }},EXTERNAL://${HOST_IP}:$(({{ .Values.externalAccess.initNodePort }} + ${KAFKA_BROKER_ID})) && \
          {{- end }}
          rm -rf /var/lib/kafka/data/lost+found && \
          exec /etc/confluent/docker/run
        ports:
        - name: tcp-kafka-int
          containerPort: {{ .Values.port.kafkaInternal }}
        - name: tcp-kafka-ext
          containerPort: {{ .Values.port.kafkaExternal }}
        {{- if .Values.livenessProbe.enabled }}
        livenessProbe:
          tcpSocket:
            port: tcp-kafka-int
          initialDelaySeconds: {{ .Values.livenessProbe.initialDelaySeconds }}
          periodSeconds: {{ .Values.livenessProbe.periodSeconds }}
          timeoutSeconds: {{ .Values.livenessProbe.timeoutSeconds }}
          successThreshold: {{ .Values.livenessProbe.successThreshold }}
          failureThreshold: {{ .Values.livenessProbe.failureThreshold }}
        {{- end }}
        {{- if .Values.readinessProbe.enabled }}
        readinessProbe:
          tcpSocket:
            port: tcp-kafka-int
          initialDelaySeconds: {{ .Values.readinessProbe.initialDelaySeconds }}
          periodSeconds: {{ .Values.readinessProbe.periodSeconds }}
          timeoutSeconds: {{ .Values.readinessProbe.timeoutSeconds }}
          successThreshold: {{ .Values.readinessProbe.successThreshold }}
          failureThreshold: {{ .Values.readinessProbe.failureThreshold }}
        {{- end }}
        volumeMounts:
        - name: data
          mountPath: /var/lib/kafka/data
        - name: config
          mountPath: /etc/kafka
        - name: logs
          mountPath: /var/log
        securityContext:
          {{- toYaml .Values.securityContext | nindent 12 }}
        resources:
          {{- toYaml .Values.resources | nindent 12 }}
      volumes:
      - name: config
        emptyDir: {}
      - name: logs
        emptyDir: {}
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: {{ .Values.diskSize | quote }}
